name: Deploy DAGs to Cloud Composer

on:
  push:
    paths:
      - 'airflow-local/dags/**'

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Authenticate with Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: '${{ secrets.GCP_SA_KEY }}'

      - name: Set up environment variables
        run: |
          echo "PROJECT_ID=${{ vars.GCP_PROJECT_ID }}" >> $GITHUB_ENV
          echo "BUCKET_NAME=${{ vars.GCS_BUCKET_NAME }}" >> $GITHUB_ENV

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dbt
        run: |
          python -m pip install --upgrade pip
          pip install dbt-core

      - name: Upload DAGs to GCS (Use gcloud storage instead of gsutil)
        run: |
          gcloud storage rsync airflow-local/dags gs://${BUCKET_NAME}/dags --recursive --delete-unmatched-destination-objects --checksums-only

      - name: Compile dbt for making manifest file
        run: |
          cd airflow-local/dags/dbt && dbt compile
          gcloud storage cp target/manifest.json gs://${BUCKET_NAME}/dags/target/manifest.json
